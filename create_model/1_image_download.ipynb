{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download train images from google search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import os\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a list of criteria to download images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "styles = [\n",
    "    'henri iv', 'louis xiii', 'louis xiv', 'louis xv', 'louis xvi',\n",
    "    'french empire', 'art nouveau', 'art deco'\n",
    "]\n",
    "\n",
    "furnitures = [\n",
    "    'chair','table','furniture','antique','desk',\n",
    "    'bookcase','sofa','meuble','style','armchair',\n",
    "    'antiquite','commode','gueridon','armoire','upholstery'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download a list of unique image urls from Google via requests and Beautifoul Soup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_url(criterion):\n",
    "    \"\"\"\n",
    "    create a url to query 20 Google images\n",
    "    \"\"\"\n",
    "    start = 'https://www.google.com/search?q='\n",
    "    mid = '+'.join(criterion.split(' '))\n",
    "    end = '&source=lnms&tbm=isch&sa=X&ved=0ahUKEwiF3qqzpYzcAhUHwVQKHX6PB5EQ_AUICygC&biw=1242&bih=715'\n",
    "    return start + mid + end\n",
    "\n",
    "def extract_img_src(data):\n",
    "    \"\"\"\n",
    "    generates a list of urls\n",
    "    each url being a link to an image from data\n",
    "    data being the results from the Google Image query\n",
    "    \"\"\"\n",
    "    image_urls = []\n",
    "    soup = BeautifulSoup(data.content,\"html.parser\")\n",
    "    images = soup.find_all('img')\n",
    "    return [image['src'] for image in images]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "for style in styles:\n",
    "    for furniture in furnitures:\n",
    "        criterion = style + ' ' + furniture\n",
    "        url = build_url(criterion)\n",
    "        data = requests.get(url)\n",
    "        img_src = extract_img_src(data)\n",
    "        criterion_df = pd.DataFrame()\n",
    "        criterion_df['img_src'] = img_src\n",
    "        criterion_df['style'] = style\n",
    "        df = pd.concat([df,criterion_df], axis=0)\n",
    "\n",
    "df = df.reset_index(drop=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's clean the dataset a bit. First 'henri iv' and 'louis xiii' can be grouped into one style, like 'louis xiv and 'louis xv' or 'louis xvi' and 'french empire'.\n",
    "\n",
    "Also some images may appear in different search results.\n",
    "- if it's for the same style search, the image is simply very representative of the style. It must be deduplicated.\n",
    "- if it's for several style searches, it's probably a mistake. The image must be removed completely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sav = df.copy()\n",
    "sav.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group stles\n",
    "df.loc[df['style'].isin(['henri iv','louis xiii']), 'style'] = 'louis xiii' \n",
    "df.loc[df['style'].isin(['louis xiv','louis xv']), 'style'] = 'baroque' \n",
    "df.loc[df['style'].isin(['louis xvi','french empire']), 'style'] = 'neoclassical' \n",
    "\n",
    "# deduplicate image sources within a style\n",
    "styles = df['style'].unique()\n",
    "style_dfs = [df.loc[df['style']==style,:] for style in styles]\n",
    "style_dfs = [sd.drop_duplicates(keep='first') for sd in style_dfs]\n",
    "df = pd.concat(style_dfs)\n",
    "\n",
    "# remove duplicates accross styles\n",
    "df = df.drop_duplicates(subset = 'img_src',keep=False)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the images in different folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_img(url,path):\n",
    "    \"\"\"\n",
    "    download the images localy\n",
    "    \"\"\"\n",
    "    data = requests.get(url).content\n",
    "    with open(path, 'wb') as f:\n",
    "            f.write(data)\n",
    "    return\n",
    "\n",
    "styles = df['style'].unique()\n",
    "try:\n",
    "    os.mkdir('data')\n",
    "except:\n",
    "    pass\n",
    "\n",
    "for style in styles:\n",
    "    i = 0\n",
    "    if style in os.listdir('data'):\n",
    "        pass\n",
    "    else:\n",
    "        os.mkdir(os.path.join('data',style))\n",
    "    img_urls = df.loc[df['style']==style,'img_src']\n",
    "    for img_url in img_urls:\n",
    "        filename = str(i) + '.jpg'\n",
    "        path = os.path.join('data',style,filename)\n",
    "        download_img(img_url,path)\n",
    "        i = i + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the images between a train and test folder (architecture required to train Keras models)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reclass images\n",
    "for style in styles:\n",
    "    if not os.path.exists(os.path.join('data','train',style)):\n",
    "        os.makedirs(os.path.join('data','train',style))\n",
    "    if not os.path.exists(os.path.join('data','validation',style)):\n",
    "        os.makedirs(os.path.join('data','validation',style))\n",
    "    imgs = os.listdir(os.path.join('data',style))\n",
    "    print(style)\n",
    "    print(len(imgs))\n",
    "    random.shuffle(imgs)\n",
    "    train = imgs[0:140]\n",
    "    validation = imgs[140:202]\n",
    "    for img in train:\n",
    "        source = os.path.join('data',style,img)\n",
    "        target = os.path.join('data','train', style,img)\n",
    "        shutil.copyfile(source,target)\n",
    "    for img in validation:\n",
    "        source = os.path.join('data',style,img)\n",
    "        target = os.path.join('data','validation', style,img)\n",
    "        shutil.copyfile(source,target)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
