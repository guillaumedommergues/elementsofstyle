{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
    "from keras import backend as k \n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define some variables. \n",
    "<ul>\n",
    "<li>The styles are the categories defined in the \"1_image_download\" notebook.</li>\n",
    "<li> The image width and height is dicated by the type of network we will fine tune, in this case Resnet 50.</li>\n",
    "<li>The batch size depends on your processor, it must be high enough to optimize speed and low enough not to run out of memory.</li>\n",
    "<li>The number of epoch depends on how long it takes for the model to converge, in our case 100 epochs works</li>\n",
    "<li>The count of categories, and of images in the train and validation dirs is dictated by the count of images previously downloade.</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define variables\n",
    "styles = [\n",
    "    'art deco', 'art nouveau', 'baroque',\n",
    "    'louis xiii', 'neoclassical'\n",
    "]\n",
    "img_width, img_height = 256, 256\n",
    "batch_size = 16\n",
    "epochs = 100\n",
    "train_dir = 'data/train'\n",
    "validation_dir = 'data/validation'\n",
    "n_cat = len(styles)\n",
    "n_train = 150*5\n",
    "n_val = 50*5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load a pre-trained model, add custom layers, compile it.<br>\n",
    "The callbacks are run afer each epoch. Checkpoint will save the best model, early will stop the training when the model converges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = applications.ResNet50(weights=\"imagenet\",\n",
    "    include_top=False,\n",
    "    input_shape = (img_width, img_height, 3)\n",
    ")\n",
    "\n",
    "# Freeze the layers which you don't want to train. Here I am freezing the first 5 layers.\n",
    "for layer in model.layers[:5]:\n",
    "    layer.trainable = False\n",
    "\n",
    "#Adding custom Layers \n",
    "x = model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(1024, activation=\"relu\")(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(1024, activation=\"relu\")(x)\n",
    "predictions = Dense(n_cat, activation=\"softmax\")(x)\n",
    "\n",
    "# creating the final model \n",
    "model_final = Model(input = model.input, output = predictions)\n",
    "\n",
    "# compile the model \n",
    "model_final.compile(\n",
    "    loss = \"categorical_crossentropy\",\n",
    "    optimizer = optimizers.SGD(lr=0.0001, momentum=0.9), \n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "# define callbacks\n",
    "checkpoint = ModelCheckpoint(\"resnet_1.h5\", monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=10, verbose=1, mode='auto')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create generators to augment data and send it to the model from the train and validation directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "rescale = 1./255, # makes pixel values be between [0,1] \n",
    "horizontal_flip = True,\n",
    "fill_mode = \"nearest\",\n",
    "zoom_range = 0.3,\n",
    "width_shift_range = 0.3,\n",
    "height_shift_range=0.3,\n",
    "rotation_range=30)\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "rescale = 1./255,\n",
    "horizontal_flip = True,\n",
    "fill_mode = \"nearest\",\n",
    "zoom_range = 0.3,\n",
    "width_shift_range = 0.3,\n",
    "height_shift_range=0.3,\n",
    "rotation_range=30)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "train_dir,\n",
    "target_size = (img_height, img_width),\n",
    "batch_size = batch_size, \n",
    "class_mode = \"categorical\")\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "validation_dir,\n",
    "target_size = (img_height, img_width),\n",
    "class_mode = \"categorical\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_final.fit_generator(\n",
    "train_generator,\n",
    "samples_per_epoch = n_train,\n",
    "epochs = epochs,\n",
    "validation_data = validation_generator,\n",
    "nb_val_samples = n_val,\n",
    "callbacks = [checkpoint, early]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "import os\n",
    "import numpy as np\n",
    "from keras.applications import imagenet_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model = load_model('resnet_1.h5')\n",
    "dirs = [dirname for dirname in os.listdir('data/validation') if not dirname.startswith('.')]\n",
    "styles = [\n",
    "    'art deco', 'art nouveau', 'baroque',\n",
    "    'louis xiii', 'neoclassical'\n",
    "]\n",
    "\n",
    "for dirname in dirs:\n",
    "    counter = 1\n",
    "    print('style to test')\n",
    "    print(dirname)\n",
    "    for file_name in os.listdir('data/validation/' + dirname):\n",
    "        if not file_name.startswith('.'):\n",
    "            img_path = os.path.join('data','validation',dirname,file_name)\n",
    "            counter = counter + 1\n",
    "            img_width, img_height = 256, 256\n",
    "            img = load_img(img_path, target_size=(img_width, img_height))\n",
    "            if img.mode != \"RGB\":\n",
    "                img = img.convert(\"RGB\")\n",
    "\n",
    "            x = img_to_array(img)\n",
    "            x = np.expand_dims(x, axis=0) # to make it nfeature, width, height, channels\n",
    "            x = x/255\n",
    "            prediction = test_model.predict(x)\n",
    "            prediction = prediction.argmax(axis=-1)[0]\n",
    "            print(styles[prediction])            \n",
    "            if counter == 5:\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save model architecture as json to save time when loading it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('model.h5')\n",
    "model_json = model.to_json()\n",
    "with open('model.json', \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "json_file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
